# pyKT-Unlearn 项目开发文档

## 1. 引言与目标

### 1.1. 项目背景
知识追踪（Knowledge Tracing）是教育技术领域的关键研究方向。`pyKT` 作为一个功能强大的开源工具库，为深度学习知识追踪模型的基准测试提供了便利。然而，随着数据隐私和模型修正需求的日益增长，如何从已训练好的复杂模型中高效、可靠地移除特定数据的影响，即机器遗忘（Machine Unlearning），已成为新的研究热点。

### 1.2. 项目目标
本项目是在 `pyKT` 基础上进行的一次深度二次开发，其核心目标是将前沿的机器遗忘功能集成到知识追踪领域。我们致力于打造一个端到端的自动化实验平台，覆盖从数据处理、模型训练、模型遗忘到结果评估的全流程，为研究者提供一个完整、灵活且可复现的机器遗忘研究工作流。

## 2. 系统架构与核心模块

为了实现上述目标，我们对系统进行了模块化设计，主要包含数据预处理、训练/遗忘引擎和统一评估框架三个核心部分。

- **数据预处理模块**: 负责处理原始数据，并根据用户配置自动生成适用于遗忘实验的保留集、遗忘集及其专属测试集。
- **训练与遗忘引擎**: 这是系统的核心，被重构为一个智能任务分发器。它能够解析用户意图，执行标准的模型训练，或调用 `Unlearner` 模块执行指定的遗忘算法。
- **统一评估框架**: 负责加载训练或遗忘后的模型，并在不同维度（如标准测试集、保留集测试集、遗忘集测试集）上进行性能评估。

## 3. 模块详细设计与实现

### 3.1. 机器遗忘核心 (`Unlearner.py`)

为了实现遗忘算法的通用性和可扩展性，我们设计并开发了 `pykt/utils/Unlearner.py` 模块。

该模块被设计为一个即插即用的处理器，它接收一个预训练好的 `pyKT` 模型实例，并提供一个统一的 `unlearn()` 接口来执行不同的遗忘策略。其关键设计在于，所有遗忘算法的实现都依赖于 `pyKT` 中通用的 `model_forward` 函数来计算模型损失和梯度，从而确保了 `Unlearner` 模块无需为每个知识追踪模型编写特定代码，实现了对 `DKT`, `AKT`, `SAINT` 等所有模型的广泛兼容。

目前，`Unlearner` 模块集成了以下主流算法：

* **精准手术式遗忘 (`_execute_surgical`)**: 该方法首先分别在保留集和遗忘集上计算费雪信息矩阵（Fisher Information Matrix），然后利用这两个矩阵的差异来精确地擦除遗忘集在模型参数上留下的梯度印记。
* **梯度上升式遗忘 (`_execute_ascent`)**: 该方法通过在遗忘集上执行梯度上升（而不是梯度下降）来反向更新模型，从而“抵消”遗忘数据的贡献。
* **微调式遗忘 (`_execute_finetune`)**: 该方法冻结模型大部分参数，仅在保留集上对指定的最后几层（如输出层）进行微调，是一种高效的近似遗忘方法。

### 3.2. 数据预处理模块 (`split_datasets.py`)

我们对 `pykt/preprocess/split_datasets.py` 进行了关键扩展，以自动化生成研究所需的特定数据集。通过 `--gen_forget_data` 参数激活此功能后，脚本可以接收 `--forget_ratio` (遗忘比例) 和 `--forget_strategy` (划分策略) 参数。

其核心创新在于**自动化生成对应的测试集**。当功能被激活时，脚本不仅将原始训练集划分为用于训练的保留集（`retain_df`）和遗忘集（`forget_df`），还会复制这两个数据子集，并将其处理成与原始测试集格式完全相同的测试文件。这一功能解决了机器遗忘研究中的一个关键痛点：它使得我们可以在遗忘操作完成后，分别在“本应保留的数据”和“本应遗忘的数据”上进行准确的性能评估，为衡量遗忘效果提供了坚实的数据基础。

### 3.3. 训练与任务分发引擎 (`wandb_train.py`)

原有的训练脚本被重构为一个功能强大的、由参数驱动的智能任务分发器。

脚本的核心逻辑由 `--unlearn_method` 参数驱动。若未提供该参数，则执行标准的模型训练流程。若提供，则根据其值（如 `retrain`, `surgical`, `ascent`, `finetune`）执行相应的遗忘任务。例如，当值为 `retrain` 时，系统会在保留集上从头训练一个模型作为基准；当值为 `surgical` 等时，系统会加载预训练模型，并调用 `Unlearner` 模块执行遗忘。

此外，该引擎实现了三级参数覆盖机制（命令行 > 模型专属配置 > 全局配置），确保了高度的灵活性和可复现性。无论执行何种任务，最终的模型检查点和完整的运行配置文件都会被保存在一个唯一的目录中，便于追溯。

### 3.4. 统一评估框架 (`wandb_predict.py`)

为了配合新的训练/遗忘工作流，`examples/wandb_predict.py` 也进行了同步重构。

最主要的增强是其**对遗忘评估的内建支持**。通过新增的 `--unlearn_test_file` (`forget` 或 `retain`)、`--unlearn_strategy` 和 `--forget_ratio` 等参数，评估脚本能够自动定位并加载在数据预处理阶段生成的特定测试集（例如 `test_sequences_forget_random_ratio0.2.csv`）。

同时，脚本的配置加载逻辑也更加健壮，它会从指定的模型保存目录中读取 `config.json` 文件，恢复模型结构和数据处理所需的所有原始参数，确保评估环境与训练环境的一致性。新增的 `--debug` 标志则可以在关键节点激活 `pdb` 调试器，极大地便利了开发和问题排查。

## 4. 实验管理与可复现性

本项目深度整合了 `WandB` (Weights & Biases)。无论是标准训练还是机器遗忘实验，所有关键的命令行参数、合并后的最终配置、性能指标（AUC/ACC）以及模型保存路径都会被自动记录到云端。这为复杂的实验管理、结果对比和团队协作提供了极大的便利，是保障研究工作可复现性的重要一环。

## 5. 结论

通过本次二次开发，`pyKT` 已从一个单纯的知识追踪模型库，演进为一个功能完备的**机器遗忘研究平台**。自动化的数据处理、模块化的算法实现、智能化的任务分发以及一体化的实验管理，共同构成了一个高效、灵活且强大的研究工具，能够显著加速在知识追踪领域开展机器遗忘相关研究的进程。